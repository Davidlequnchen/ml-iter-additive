{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math,os\n",
    "from numpy.random import choice\n",
    "import scikitplot as skplt\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Ridge,SGDRegressor,ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.validation import check_array \n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor,GradientBoostingRegressor,AdaBoostRegressor,BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "historicalColumns,neighborColumns,neighborColumnsAggregated = [],[],[]\n",
    "\n",
    "for historical in range(5):\n",
    "    historicalColumns += ['Tminus'+str(historical+1)]\n",
    "\n",
    "for neighbor in range(26):\n",
    "    neighborColumns += ['T'+str(neighbor+1)+'_t-1']\n",
    "    \n",
    "for neighborDegree in range(3):\n",
    "        neighborColumnsAggregated += ['T_nbhDeg'+str(neighborDegree+1)+'_t-1']\n",
    "\n",
    "columns = ['voxelLat','voxelLong','voxelVert','voxelType','timestep','x_voxel','y_voxel','z_voxel','layerNum','time_creation', 'time_elapsed', 'x_laser','y_laser','z_laser','x_distance','y_distance','z_distance','euclidean_distance_laser'] + historicalColumns+ neighborColumns + neighborColumnsAggregated + ['T_self']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundup(a, digits=4):\n",
    "    n = 10**-digits\n",
    "    return round(math.ceil(a / n) * n, digits)\n",
    "\n",
    "def isEven(num):\n",
    "    if num%2 ==0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def modLog(num):\n",
    "    try:\n",
    "        return log(num)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def loadNumpy(name,path='.'):\n",
    "    if \".npy\" in name:\n",
    "        fullPath = path+'/'+name\n",
    "    else:\n",
    "        fullPath = path+'/'+name+'.npy'\n",
    "    return np.load(fullPath, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureColumns = ['timestep','x_distance','y_distance','z_distance','time_elapsed'] + historicalColumns + neighborColumns\n",
    "featureDisplay = featureColumns\n",
    "\n",
    "# featureDisplay[7] = 'T_immediate_x-1'\n",
    "# featureDisplay[8] = 'T_immediate_x+1'\n",
    "# featureDisplay[9] = 'T_immediate_y-1'\n",
    "# featureDisplay[10] = 'T_immediate_y+1'\n",
    "# featureDisplay[11] = 'T_immediate_z-1'\n",
    "\n",
    "# featureDisplay[13] = 'T_immediate_x-1,y-1'\n",
    "# featureDisplay[14] = 'T_immediate_x-1,y+1'\n",
    "# featureDisplay[15] = 'T_immediate_x+1,y-1'\n",
    "# featureDisplay[16] = 'T_immediate_x+1,y+1'\n",
    "\n",
    "# featureDisplay[21] = 'T_immediate_x-1,z-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(et):\n",
    "    skplt.estimators.plot_feature_importances(et,text_fontsize=16,max_num_features=6,figsize=(24,4),feature_names=featureDisplay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "\t'''\n",
    "\tscikit(sklearn) does not have support for mean absolute percentage error MAPE.\n",
    "\tThis is because the denominator can theoretically be 0 and so the value would be undefined.\n",
    "\tSo this is our implementation\n",
    "\t'''\n",
    "# \ty_true = check_array(y_true)\n",
    "# \ty_pred = check_array(y_pred)\n",
    "\n",
    "\treturn np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def r2(y_true,y_pred):\n",
    "    return roundup(r2_score(y_true,y_pred))\n",
    "\n",
    "def mse(y_true,y_pred):\n",
    "    return roundup(mean_squared_error(y_true,y_pred))\n",
    "\n",
    "def mae(y_true,y_pred):\n",
    "    return roundup(mean_absolute_error(y_true,y_pred))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    return roundup(mean_absolute_percentage_error(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineDataFrames(prefix,columns=columns):\n",
    "    List = []\n",
    "    nums_start,nums_stop = [],[]\n",
    "    for item in os.listdir('../data/cube-20-20-10-800-processed'):\n",
    "        if \"cubeAgg-20-20-10-800_\" in item and \".npy\" in item:\n",
    "            timeStep_start = int(item.split('cubeAgg-20-20-10-800_')[1].split('_')[0])\n",
    "            nums_start += [timeStep_start]\n",
    "            \n",
    "            timeStep_stop = int(item.split('_')[2].split('.npy')[0])\n",
    "            nums_stop += [timeStep_stop]\n",
    "            \n",
    "    nums_start = sorted(nums_start)\n",
    "    nums_stop = sorted(nums_stop)\n",
    "    \n",
    "#     print (nums_start)\n",
    "#     print (nums_stop)\n",
    "    \n",
    "    array = loadNumpy('../data/cube-20-20-10-800-processed/'+prefix+'_'+str(nums_start[0])+'_'+str(nums_stop[0])+'.npy')\n",
    "    for i in range(1,len(nums_start)):\n",
    "        newFile = '../data/cube-20-20-10-800-processed/'+prefix+'_'+str(nums_start[i])+'_'+str(nums_stop[i])+'.npy'\n",
    "        array = np.append(array,loadNumpy(newFile),axis=0)\n",
    "    return pd.DataFrame(array,columns=columns)\n",
    "\n",
    "\n",
    "# def combineDataFrames(columns=columns):\n",
    "#     dir = './temp/'\n",
    "#     array = loadNumpy(dir+'file1.npy')\n",
    "#     array = np.append(array,loadNumpy(dir+'file2.npy'),axis=0)\n",
    "    \n",
    "#     return pd.DataFrame(array,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_big = combineDataFrames('cubeAgg-20-20-10-800')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Prediction (Trail Run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1 = df_big[df_big.timestep < 200.0]\n",
    "df_test_1 = df_big[(df_big.timestep >= 200.0) & (df_big.timestep < 220.0)]\n",
    "\n",
    "# featureColumns = ['timestep','x_distance','y_distance','z_distance','layerNum','Tminus1','Tminus2']+neighborColumns\n",
    "\n",
    "X_train_1, y_train_1= shuffle(df_train_1.loc[:,featureColumns ], df_train_1['T_self'].values, random_state=300)\n",
    "X_test_1,y_test_1 = shuffle(df_test_1.loc[:,featureColumns],df_test_1['T_self'],random_state=300)\n",
    "\n",
    "et_1 = ExtraTreesRegressor(n_estimators=10, n_jobs=-1,random_state=300)\n",
    "et_1.fit(X_train_1,y_train_1)\n",
    "y_predicted_1 = et_1.predict(X_test_1)\n",
    "print('Iteration 1 over....')\n",
    "\n",
    "X_train_2, y_train_2= X_train_1.append(X_test_1, ignore_index=True), np.append( y_train_1, y_predicted_1)\n",
    "X_train_2,y_train_2 = shuffle(X_train_2,y_train_2,random_state=300)\n",
    "\n",
    "df_test_2 = df_big[(df_big.timestep >= 220.0) & (df_big.timestep < 240.0)]\n",
    "X_test_2,y_test_2 = shuffle(df_test_2.loc[:,featureColumns],df_test_2['T_self'],random_state=300)\n",
    "\n",
    "et_2 = ExtraTreesRegressor(n_estimators=10, n_jobs=-1,random_state=300)\n",
    "et_2.fit(X_train_2,y_train_2)\n",
    "y_predicted_2 = et_2.predict(X_test_2)\n",
    "print('Iteration 2 over....')\n",
    "\n",
    "X_train_3, y_train_3= X_train_2.append(X_test_2, ignore_index=True), np.append( y_train_2, y_predicted_2)\n",
    "X_train_3,y_train_3 = shuffle(X_train_3,y_train_3,random_state=300)\n",
    "\n",
    "df_test_3 = df_big[(df_big.timestep >= 240.0) & (df_big.timestep < 260.0)]\n",
    "X_test_3,y_test_3 = shuffle(df_test_3.loc[:,featureColumns],df_test_3['T_self'],random_state=300)\n",
    "\n",
    "et_3 = ExtraTreesRegressor(n_estimators=10, n_jobs=-1,random_state=300)\n",
    "et_3.fit(X_train_3,y_train_3)\n",
    "y_predicted_3 = et_3.predict(X_test_3)\n",
    "print('Iteration 3 over....')\n",
    "\n",
    "X_train_4, y_train_4= X_train_3.append(X_test_3, ignore_index=True), np.append( y_train_3, y_predicted_3)\n",
    "X_train_4,y_train_4 = shuffle(X_train_4,y_train_4,random_state=300)\n",
    "\n",
    "df_test_4 = df_big[(df_big.timestep >= 260.0) & (df_big.timestep < 280.0)]\n",
    "X_test_4,y_test_4 = shuffle(df_test_4.loc[:,featureColumns],df_test_4['T_self'],random_state=300)\n",
    "\n",
    "et_4 = ExtraTreesRegressor(n_estimators=10, n_jobs=-1,random_state=300)\n",
    "et_4.fit(X_train_4,y_train_4)\n",
    "y_predicted_4 = et_4.predict(X_test_4)\n",
    "print('Iteration 4 over....')\n",
    "\n",
    "X_train_5, y_train_5= X_train_4.append(X_test_4, ignore_index=True), np.append( y_train_4, y_predicted_4)\n",
    "X_train_5,y_train_5 = shuffle(X_train_5,y_train_5,random_state=300)\n",
    "\n",
    "df_test_5 = df_big[(df_big.timestep >= 280.0) & (df_big.timestep < 300.0)]\n",
    "X_test_5,y_test_5 = shuffle(df_test_5.loc[:,featureColumns],df_test_5['T_self'],random_state=300)\n",
    "\n",
    "et_5 = ExtraTreesRegressor(n_estimators=10, n_jobs=-1,random_state=300)\n",
    "et_5.fit(X_train_5,y_train_5)\n",
    "y_predicted_5 = et_5.predict(X_test_5)\n",
    "print('Iteration 5 over....')\n",
    "\n",
    "\n",
    "print ('Iterative training results')\n",
    "print r2(y_test_1,y_predicted_1), mape(y_test_1,y_predicted_1)\n",
    "print r2(y_test_2,y_predicted_2), mape(y_test_2,y_predicted_2)\n",
    "print r2(y_test_3,y_predicted_3), mape(y_test_3,y_predicted_3)\n",
    "print r2(y_test_4,y_predicted_4), mape(y_test_4,y_predicted_4)\n",
    "print r2(y_test_5,y_predicted_5), mape(y_test_5,y_predicted_5)\n",
    "\n",
    "print ('One step training results')\n",
    "et_direct = ExtraTreesRegressor(n_estimators=10, n_jobs=-1,random_state=300)\n",
    "et_direct.fit(X_train_1,y_train_1)\n",
    "y_predicted = et_direct.predict(X_test_5)\n",
    "\n",
    "r2(y_test_5,y_predicted) ,mape(y_test_5,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative vs Non-iterative prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_iterative_direct_prediction(n=5, init=100, TIMESTEP_ITER = 50, n_estimators=10):\n",
    "    \n",
    "    df_train_i_minus_1 = df_big[df_big.timestep < init]\n",
    "    df_test_i_minus_1 = df_big[(df_big.timestep >= init) & (df_big.timestep < init+TIMESTEP_ITER)]\n",
    "#     print (df_test_i_minus_1)\n",
    "\n",
    "    X_train_i_minus_1, y_train_i_minus_1= shuffle(df_train_i_minus_1.loc[:,featureColumns ], df_train_i_minus_1['T_self'].values, random_state=300)\n",
    "    X_test_i_minus_1,y_test_i_minus_1 = shuffle(df_test_i_minus_1.loc[:,featureColumns],df_test_i_minus_1['T_self'],random_state=300)\n",
    "\n",
    "    et_i_minus_1 = ExtraTreesRegressor(n_estimators=n_estimators, n_jobs=-1,random_state=300)\n",
    "    start = time()\n",
    "    et_i_minus_1.fit(X_train_i_minus_1,y_train_i_minus_1)\n",
    "    y_predicted_i_minus_1 = et_i_minus_1.predict(X_test_i_minus_1)\n",
    "    \n",
    "    START = init\n",
    "    STOP = init + TIMESTEP_ITER\n",
    "    \n",
    "#     print (\"START is: \",START)\n",
    "#     print (\"STOP is: \", STOP)\n",
    "    \n",
    "#     print (\"r2 is: \",r2(y_test_i_minus_1,y_predicted_i_minus_1) , \"mape is: \", mape(y_test_i_minus_1,y_predicted_i_minus_1))\n",
    "    \n",
    "    temp_y = y_test_i_minus_1\n",
    "    temp_predicted = y_predicted_i_minus_1\n",
    "\n",
    "    print('Iteration 1 over....')\n",
    "#     print('\\n')\n",
    "    \n",
    "    \n",
    "    for i in range(2,n+1):\n",
    "        X_train_i, y_train_i= X_train_i_minus_1.append(X_test_i_minus_1, ignore_index=True), np.append(y_train_i_minus_1, y_predicted_i_minus_1)\n",
    "#         print(X_train_i.iloc[:,0:2].tail(50))\n",
    "#         print(X_train_i_minus_1.iloc[:,0:2].tail(50))\n",
    "        X_train_i,y_train_i = shuffle(X_train_i,y_train_i,random_state=300)\n",
    "        START = START + TIMESTEP_ITER\n",
    "        STOP = STOP + TIMESTEP_ITER\n",
    "#         print (\"START is: \",START)\n",
    "#         print (\"STOP is: \", STOP)\n",
    "        df_test_i = df_big[(df_big.timestep >= START) & (df_big.timestep < STOP)]\n",
    "#         print (df_test_i)\n",
    "        X_test_i,y_test_i = shuffle(df_test_i.loc[:,featureColumns],df_test_i['T_self'],random_state=300)\n",
    "\n",
    "        et_i = ExtraTreesRegressor(n_estimators=n_estimators, n_jobs=-1,random_state=300)\n",
    "        et_i.fit(X_train_i,y_train_i)\n",
    "        y_predicted_i = et_i.predict(X_test_i)\n",
    "#         print (\"r2 is: \", r2(y_test_i,y_predicted_i),\"mape is: \",mape(y_test_i,y_predicted_i))\n",
    "        \n",
    "        temp_y = temp_y.append(y_test_i)\n",
    "        temp_predicted = np.append(temp_predicted,y_predicted_i)\n",
    "        \n",
    "        X_train_i_minus_1 = X_train_i\n",
    "        X_test_i_minus_1 = X_test_i\n",
    "        y_train_i_minus_1 = y_train_i\n",
    "#         y_test_i_minus_1 = y_test_i\n",
    "        y_predicted_i_minus_1 = y_predicted_i\n",
    "        \n",
    "        print('Iteration '+str(i)+' over....')\n",
    "#         print('\\n')\n",
    "#         if i==2:\n",
    "#             break\n",
    "\n",
    "    stop = time()\n",
    "#     print ('time elapsed for iterative is ',(stop-start),'seconds')\n",
    "#     print ('\\n')\n",
    "\n",
    "#     print (r2(y_test_i,y_predicted_i) ,mape(y_test_i,y_predicted_i))\n",
    "\n",
    "    print('\\n')\n",
    "    print ('Iterative Prediction Accuracy for all timesteps predicted: ')\n",
    "    \n",
    "#     print (temp_y)\n",
    "#     print (temp_predicted)\n",
    "    \n",
    "#     print (len(temp_y),len(temp_predicted))\n",
    "    \n",
    "    print (\"r2 is: \", r2(temp_y,temp_predicted) ,\"mape is: \", mape(temp_y,temp_predicted))    \n",
    "    print('\\n')\n",
    "    \n",
    "\n",
    "    print ('Non-iterative accuracy for last TIME_STEP_ITER timesteps: ')\n",
    "    df_train_1 = df_big[df_big.timestep < init]\n",
    "    X_train_1, y_train_1= shuffle(df_train_1.loc[:,featureColumns ], df_train_1['T_self'].values, random_state=300)\n",
    "    start = time()\n",
    "    et_direct = ExtraTreesRegressor(n_estimators=n_estimators, n_jobs=-1,random_state=300)\n",
    "    et_direct.fit(X_train_1,y_train_1)\n",
    "    y_predicted_direct = et_direct.predict(X_test_i)\n",
    "\n",
    "    stop = time()\n",
    "#     print ('time elapsed for direct is ',(stop-start),'seconds')\n",
    "    print (\"r2 is: \", r2(y_test_i,y_predicted_direct), \"mape is: \", mape(y_test_i,y_predicted_direct))\n",
    "    print('\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "    print ('Non-iterative accuracy for all timesteps predicted: ')\n",
    "    \n",
    "    df_train = df_big[df_big['timestep'] < init]\n",
    "    df_test = df_big[(df_big['timestep'] >= init) & (df_big['timestep'] < (init+ (TIMESTEP_ITER * n) ))]\n",
    "\n",
    "\n",
    "    X_train = df_train.loc[:,featureColumns]\n",
    "    y_train = df_train['T_self']\n",
    "\n",
    "    X_test = df_test.loc[:,featureColumns]\n",
    "    y_test = df_test['T_self']\n",
    "\n",
    "    X_train,y_train = shuffle(X_train,y_train,random_state=300)\n",
    "    X_test,y_test = shuffle(X_test,y_test,random_state=300)\n",
    "    \n",
    "    et_direct = ExtraTreesRegressor(n_estimators=n_estimators, n_jobs=-1,random_state=300)\n",
    "    et_direct.fit(X_train,y_train)\n",
    "    predicted = et_direct.predict(X_test)\n",
    "    print (\"r2 is: \", r2(y_test,predicted), \"mape is: \", mape(y_test,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 over....\n",
      "Iteration 2 over....\n",
      "Iteration 3 over....\n",
      "Iteration 4 over....\n",
      "Iteration 5 over....\n",
      "Iteration 6 over....\n",
      "Iteration 7 over....\n",
      "Iteration 8 over....\n",
      "Iteration 9 over....\n",
      "Iteration 10 over....\n",
      "\n",
      "\n",
      "Iterative Prediction Accuracy for all timesteps predicted: \n",
      "r2 is:  0.9601 mape is:  2.9672\n",
      "\n",
      "\n",
      "Non-iterative accuracy for last TIME_STEP_ITER timesteps: \n",
      "r2 is:  0.9183 mape is:  3.2508\n",
      "\n",
      "\n",
      "Non-iterative accuracy for all timesteps predicted: \n",
      "r2 is:  0.9614 mape is:  2.4556\n"
     ]
    }
   ],
   "source": [
    "compare_iterative_direct_prediction(n=10,init=200,TIMESTEP_ITER=20,n_estimators=10) # No of iterations, Initial timestep to start prediction, No of timesteps for which temperatures are to be predicted in each interatino, No of estimators in Extra Trees model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 over....\n",
      "Iteration 2 over....\n",
      "Iteration 3 over....\n",
      "Iteration 4 over....\n",
      "Iteration 5 over....\n",
      "Iteration 6 over....\n",
      "Iteration 7 over....\n",
      "Iteration 8 over....\n",
      "Iteration 9 over....\n",
      "Iteration 10 over....\n",
      "Iteration 11 over....\n",
      "Iteration 12 over....\n",
      "Iteration 13 over....\n",
      "Iteration 14 over....\n",
      "Iteration 15 over....\n",
      "Iteration 16 over....\n",
      "Iteration 17 over....\n",
      "Iteration 18 over....\n",
      "Iteration 19 over....\n",
      "Iteration 20 over....\n",
      "\n",
      "\n",
      "Iterative Prediction Accuracy for all timesteps predicted: \n",
      "r2 is:  0.9562 mape is:  2.6861\n",
      "\n",
      "\n",
      "Non-iterative accuracy for last TIME_STEP_ITER timesteps: \n",
      "r2 is:  0.8914 mape is:  3.9053\n",
      "\n",
      "\n",
      "Non-iterative accuracy for all timesteps predicted: \n",
      "r2 is:  0.9373 mape is:  3.1593\n"
     ]
    }
   ],
   "source": [
    "compare_iterative_direct_prediction(n=20,init=200,TIMESTEP_ITER=20,n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 over....\n",
      "Iteration 2 over....\n",
      "Iteration 3 over....\n",
      "Iteration 4 over....\n",
      "Iteration 5 over....\n",
      "Iteration 6 over....\n",
      "Iteration 7 over....\n",
      "Iteration 8 over....\n",
      "Iteration 9 over....\n",
      "Iteration 10 over....\n",
      "Iteration 11 over....\n",
      "Iteration 12 over....\n",
      "Iteration 13 over....\n",
      "Iteration 14 over....\n",
      "Iteration 15 over....\n",
      "Iteration 16 over....\n",
      "Iteration 17 over....\n",
      "Iteration 18 over....\n",
      "Iteration 19 over....\n",
      "Iteration 20 over....\n",
      "Iteration 21 over....\n",
      "Iteration 22 over....\n",
      "Iteration 23 over....\n",
      "Iteration 24 over....\n",
      "Iteration 25 over....\n",
      "Iteration 26 over....\n",
      "Iteration 27 over....\n",
      "Iteration 28 over....\n",
      "Iteration 29 over....\n",
      "Iteration 30 over....\n",
      "\n",
      "\n",
      "Iterative Prediction Accuracy for all timesteps predicted: \n",
      "r2 is:  0.935 mape is:  3.375\n",
      "\n",
      "\n",
      "Non-iterative accuracy for last TIME_STEP_ITER timesteps: \n",
      "r2 is:  0.822 mape is:  4.61\n",
      "\n",
      "\n",
      "Non-iterative accuracy for all timesteps predicted: \n",
      "r2 is:  0.9058 mape is:  3.5953\n"
     ]
    }
   ],
   "source": [
    "compare_iterative_direct_prediction(n=30,init=200,TIMESTEP_ITER=20,n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 over....\n",
      "Iteration 2 over....\n",
      "Iteration 3 over....\n",
      "Iteration 4 over....\n",
      "Iteration 5 over....\n",
      "Iteration 6 over....\n",
      "Iteration 7 over....\n",
      "Iteration 8 over....\n",
      "Iteration 9 over....\n",
      "Iteration 10 over....\n",
      "Iteration 11 over....\n",
      "Iteration 12 over....\n",
      "Iteration 13 over....\n",
      "Iteration 14 over....\n",
      "Iteration 15 over....\n",
      "Iteration 16 over....\n",
      "Iteration 17 over....\n",
      "Iteration 18 over....\n",
      "Iteration 19 over....\n",
      "Iteration 20 over....\n",
      "Iteration 21 over....\n",
      "Iteration 22 over....\n",
      "Iteration 23 over....\n",
      "Iteration 24 over....\n",
      "Iteration 25 over....\n",
      "Iteration 26 over....\n",
      "Iteration 27 over....\n",
      "Iteration 28 over....\n",
      "Iteration 29 over....\n",
      "Iteration 30 over....\n",
      "Iteration 31 over....\n",
      "Iteration 32 over....\n",
      "Iteration 33 over....\n",
      "Iteration 34 over....\n",
      "Iteration 35 over....\n",
      "Iteration 36 over....\n",
      "Iteration 37 over....\n",
      "Iteration 38 over....\n",
      "Iteration 39 over....\n",
      "Iteration 40 over....\n",
      "\n",
      "\n",
      "Iterative Prediction Accuracy for all timesteps predicted: \n",
      "r2 is:  0.9243 mape is:  3.0525\n",
      "\n",
      "\n",
      "Non-iterative accuracy for last TIME_STEP_ITER timesteps: \n",
      "r2 is:  0.7719 mape is:  4.22\n",
      "\n",
      "\n",
      "Non-iterative accuracy for all timesteps predicted: \n",
      "r2 is:  0.8772 mape is:  3.959\n"
     ]
    }
   ],
   "source": [
    "compare_iterative_direct_prediction(n=40,init=200,TIMESTEP_ITER=20,n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 over....\n",
      "Iteration 2 over....\n",
      "Iteration 3 over....\n",
      "Iteration 4 over....\n",
      "Iteration 5 over....\n",
      "Iteration 6 over....\n",
      "Iteration 7 over....\n",
      "Iteration 8 over....\n",
      "Iteration 9 over....\n",
      "Iteration 10 over....\n",
      "Iteration 11 over....\n",
      "Iteration 12 over....\n",
      "Iteration 13 over....\n",
      "Iteration 14 over....\n",
      "Iteration 15 over....\n",
      "Iteration 16 over....\n",
      "Iteration 17 over....\n",
      "Iteration 18 over....\n",
      "Iteration 19 over....\n",
      "Iteration 20 over....\n",
      "Iteration 21 over....\n",
      "Iteration 22 over....\n",
      "Iteration 23 over....\n",
      "Iteration 24 over....\n",
      "Iteration 25 over....\n",
      "Iteration 26 over....\n",
      "Iteration 27 over....\n",
      "Iteration 28 over....\n",
      "Iteration 29 over....\n",
      "Iteration 30 over....\n",
      "Iteration 31 over....\n",
      "Iteration 32 over....\n",
      "Iteration 33 over....\n",
      "Iteration 34 over....\n",
      "Iteration 35 over....\n",
      "Iteration 36 over....\n",
      "Iteration 37 over....\n",
      "Iteration 38 over....\n",
      "Iteration 39 over....\n",
      "Iteration 40 over....\n",
      "Iteration 41 over....\n",
      "Iteration 42 over....\n",
      "Iteration 43 over....\n",
      "Iteration 44 over....\n",
      "Iteration 45 over....\n",
      "Iteration 46 over....\n",
      "Iteration 47 over....\n",
      "Iteration 48 over....\n",
      "Iteration 49 over....\n",
      "Iteration 50 over....\n",
      "\n",
      "\n",
      "Iterative Prediction Accuracy for all timesteps predicted: \n",
      "r2 is:  0.9041 mape is:  3.4048\n",
      "\n",
      "\n",
      "Non-iterative accuracy for last TIME_STEP_ITER timesteps: \n",
      "r2 is:  0.7242 mape is:  5.3229\n",
      "\n",
      "\n",
      "Non-iterative accuracy for all timesteps predicted: \n",
      "r2 is:  0.8448 mape is:  4.2655\n"
     ]
    }
   ],
   "source": [
    "compare_iterative_direct_prediction(n=50,init=200,TIMESTEP_ITER=20,n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
